<!doctype html>
<script>

const get_node_and_reply = (context) => {
  const node = new AudioWorkletNode(context, 'port-processor');
  return new Promise((resolve) => {
    node.port.onmessage = (event) => resolve({node: node, reply: event.data});
  });
};

const modulePath = '/webaudio/the-audio-api/' +
    'the-audioworklet-interface/processors/port-processor.js';

promise_test(async t => {
  const realtime = new AudioContext();
  const sampleRate = realtime.createOscillator();
  oscillator.connect(realtime.destination);
  oscillator.start();

  // Start rendering and suspend after a delay.
  await new Promise(resolve => t.step_timeout(resolve, 1000));
  await realtime.suspend();

  // Capture currentTime after suspending.
  const contextTime = realtime.currentTime;

  // Load the audio module.
  await realtime.audioWorklet.addModule(modulePath);

  // creates AudioWorkletNode.
  const construct1 = await get_node_and_reply(realtime);

  // workletFrame should be the currentFrame sent in the message
  // by the AudioWorkletNode.
  const workletFrame = construct1.reply.curreng after resume()</title></script>
